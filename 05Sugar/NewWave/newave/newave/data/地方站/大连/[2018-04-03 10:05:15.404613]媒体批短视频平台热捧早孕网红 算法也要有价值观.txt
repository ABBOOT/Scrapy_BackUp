
				 

					


|	


|	


|	


|	


|	


|	


|	


|	


|	


|	


|	


|	



            
|
|
|
　　文 |社论
　　据央视报道，国内多个短视频平台存在大量未成年人怀孕、生子的视频，她们以此为荣，争相炫耀。记者调查发现，平台的智能推荐功能成了这些未成年妈妈背后的推手。4月1日，有平台回应记者称，已经对平台上涉及“未婚妈妈”等类似视频，进行了清理。对于自称年龄低于14岁用户的案例，平台已固定证据与有关部门沟通。
　　虽然《婚姻法》、《未成年人保护法》早已颁布实施多年，但早婚早育现象在一些农村地区长期存在是不争的事实。这其中有基层治理失序、监护人失责等多个层面的问题。未成年结婚生子，不仅挑战社会主流价值观，也突破了法律底线。
　　我们不仅要看到短视频乱象，更要看到背后的社会乱象。因此，正确善后方式不应该只是将相关视频一删了之，将相关账号一封了之。相关平台固定证据与有关部门沟通的做法，值得肯定。
　　不过，除此之外也要看到，短视频平台没有制造早婚早孕，而只是用它们的算法进行了呈现和推荐。但是，问题也出在算法上。在相当长的时间内，科技公司们一边大把赚钱，一边把“算法无罪”、“技术中立”当做万能免罪牌。但是，近年来国内外的互联网用户都逐渐意识到这其中的问题。
　　无论Facebook的用户信息泄露事件，还是前几天引发争议的“中国用户愿意用隐私换效率”，都凸显出用户权利的觉醒。人们不再把算法视作扑朔迷离的黑箱，而要进入其中一探究竟。
　　依据技术哲学专家安德鲁·芬伯格的技术批判理论，技术并不是一个中立的工具，而是会带有自己的价值观及价值偏好：因为每项技术不是来自真空，而是有特定的场景，比如：技术是由谁开发，为什么开发，技术如何运用。而公众、政府部门、科技公司也终将达成共识：算法也要有价值观，如果不给算法设置正确的价值观，它就会被错误的价值观所俘获。
　　就拿近年越来越火爆的“智能推荐”算法来说，技术名词说起来很唬人，但归根结底一句话：尽可能推荐用户想看的内容。而在算法“眼”里，所谓用户想看的内容只能根据用户看过的内容进行推导。
　　所以，你点一次未成年妈妈的视频，平台就会自动给你推荐更多未成年妈妈。算法确实没有想过“我要做坏事”，但这个推荐过程本身就体现了一种价值观——用户“想看”什么都是正当的，流量最大化才是终极目的。
　　为了流量最大化，用户隐私、法律公德就极易沦为次级目的。事实上，如果科技公司不能为自家的算法划定“不可为”的红线，那就是默认了允许算法作恶。推荐同类视频看起来只是人畜无害的功能，但早孕网红被平台热捧的事实，却让我们清晰地看到了算法的黑暗面。这些早孕的妈妈们本身就是受害者，算法却帮助她们把自己想象成受人追捧的英雄。
　　进而言之，算法在帮助人们在网上快速找到同类的同时，也很容易使人陷入封闭的信息环境难以自拔。长期上某些资讯平台、视频平台的用户，有可能失去认识更广阔的真实世界的能力，假如是本身就缺乏辨别力的青少年用户，结果可能更可怕。
　　目前，公众关于算法价值观的讨论还处于很初始的地步，但严峻的现实警告我们，不能再任由算法野蛮生长了。

http://dl.sina.com.cn/zt/auto/sinadlcyh/index.shtml